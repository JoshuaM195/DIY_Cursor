{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaM195/DIY_Cursor/blob/main/Codebase_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Screenshot 2024-11-25 at 7 12 58 PM](https://github.com/user-attachments/assets/48dd9de1-b4d2-4318-8f52-85ec209d8ebc)"
      ],
      "metadata": {
        "id": "JSQbb-WI0Nb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Necessary Libraries"
      ],
      "metadata": {
        "id": "MpmkP4rM1KRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pygithub langchain langchain-community openai tiktoken pinecone-client langchain_pinecone sentence-transformers"
      ],
      "metadata": {
        "id": "BGFWnzpBDkWH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAIXpUxWDFSV"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone\n",
        "import os\n",
        "import tempfile\n",
        "from github import Github, Repository\n",
        "from git import Repo\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from langchain.schema import Document\n",
        "from pinecone import Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone a GitHub Repo locally"
      ],
      "metadata": {
        "id": "hTLsQ9Ma1FpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "github_repo = \"https://github.com/evanng07/CodeInsight\"\n",
        "github_repo.split(\"/\")[-1]"
      ],
      "metadata": {
        "id": "MbTSPurVjr2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clone_repository(repo_url):\n",
        "    \"\"\"Clones a GitHub repository to a temporary directory.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "        The path to the cloned repository.\n",
        "    \"\"\"\n",
        "    repo_name = github_repo.split(\"/\")[-1]\n",
        "    repo_path = f\"/content/{repo_name}\"\n",
        "    Repo.clone_from(repo_url, str(repo_path))\n",
        "    return repo_path\n"
      ],
      "metadata": {
        "id": "F_1zslPsDmJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = clone_repository(github_repo)"
      ],
      "metadata": {
        "id": "hFrrr5rjEfYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOIPXbV_KvIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define which types of files to parse and which files / folders to ignore"
      ],
      "metadata": {
        "id": "7rm1vwr5KVQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUPPORTED_EXTENSIONS = {'.py', '.js', '.tsx', '.jsx', '.ipynb', '.java',\n",
        "                         '.cpp', '.ts', '.go', '.rs', '.vue', '.swift', '.c', '.h'}\n",
        "\n",
        "IGNORED_DIRS = {'node_modules', 'venv', 'env', 'dist', 'build', '.git',\n",
        "                '__pycache__', '.next', '.vscode', 'vendor'}"
      ],
      "metadata": {
        "id": "MQOcyi6DE5bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_content(file_path, repo_path):\n",
        "    \"\"\"\n",
        "    Get content of a single file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Optional[Dict[str, str]]: Dictionary with file name and content\n",
        "    \"\"\"\n",
        "    try:\n",
        "      with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "      rel_path = os.path.relpath(file_path, repo_path)\n",
        "\n",
        "      return {\n",
        "          \"name\": rel_path,\n",
        "          \"content\": content\n",
        "      }\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing file {file_path}: {str(e)}\")\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "def get_main_files_content(repo_path: str):\n",
        "    \"\"\"\n",
        "    Get content of supported code files from the local repository.\n",
        "\n",
        "    Args:\n",
        "        repo_path: Path to the local repository\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing file names and contents\n",
        "    \"\"\"\n",
        "\n",
        "    files_content = []\n",
        "\n",
        "    try:\n",
        "\n",
        "      for root, _, files in os.walk(repo_path):\n",
        "        if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\n",
        "          continue\n",
        "\n",
        "        for file in files:\n",
        "          file_path = os.path.join(root, file)\n",
        "          if os.path.splitext(file) [1] in SUPPORTED_EXTENSIONS:\n",
        "            file_content = get_file_content(file_path, repo_path)\n",
        "\n",
        "            if file_content:\n",
        "              files_content.append(file_content)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "    return files_content\n"
      ],
      "metadata": {
        "id": "qi0FbfdrF6Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_content = get_main_files_content(path)"
      ],
      "metadata": {
        "id": "5mMaHXkrKoFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_content"
      ],
      "metadata": {
        "id": "HvNX_WcUKoH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "fTHEOUgp1Nmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)"
      ],
      "metadata": {
        "id": "pRz7UnvJoL-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am learning\"\n",
        "embeddings = get_huggingface_embeddings(text)"
      ],
      "metadata": {
        "id": "oe-7UwHGvCno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "id": "QyUKZzIIK1dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6JWrh6VK1fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PINECONE_API_KEY as an environment variable\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=userdata.get(\"PINECONE_API_KEY\"),)\n",
        "\n",
        "# Connect to your Pinecone index\n",
        "pinecone_index = pc.Index(\"codebase-rag\")"
      ],
      "metadata": {
        "id": "y05YK2IjaGgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "id": "OQN1SdEQbwDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert the codebase embeddings into Pinecone\n",
        "\n",
        "documents = []\n",
        "\n",
        "for file in files_content:\n",
        "  doc = Document(\n",
        "      page_content=f\"{file['name']}\\n\\n{file['content']}\",\n",
        "      metadata={\"source\": file['name']}\n",
        "  )\n",
        "\n",
        "  documents.append(doc)\n",
        "\n",
        "\n",
        "vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    index_name=\"codebase-rag\",\n",
        "    namespace=\"https://github.com/evanng07/CodeInsight\"\n",
        ")"
      ],
      "metadata": {
        "id": "tDAB_siIb93B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "TGuQiFQmd4HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "K9DJQMc_nrsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"OPENROUTER_API_KEY\"))  # Should not be None or empty"
      ],
      "metadata": {
        "id": "ysf0yB8e2r4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is happening in this codebase?\""
      ],
      "metadata": {
        "id": "MqJtdpK_qNut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_query_embedding = get_huggingface_embeddings(query)"
      ],
      "metadata": {
        "id": "hxQHkgNSLEnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_query_embedding"
      ],
      "metadata": {
        "id": "qpsGsYUXLEpx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_mathces = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=\"https://github.com/evanng07/CodeInsight\")"
      ],
      "metadata": {
        "id": "ibfr-LsiLEsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_mathces"
      ],
      "metadata": {
        "id": "7FwqRviPqkHy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = [item['metadata']['text'] for item in top_mathces['matches']]"
      ],
      "metadata": {
        "id": "LDKAXsu1qkKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fLLCydtbzQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n--------\\n\\n\".join(context)+\"\\n---------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query"
      ],
      "metadata": {
        "id": "tDHtJlJnzQsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_query)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V152sS43zQx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are a Senior Software Engineer, who is an expert in Python and fullstack development.\n",
        "\n",
        "Answer the question I have about the codebase based on the context provided.\n",
        "Always consider all of the context provided to answer my questions.\n",
        "\"\"\"\n",
        "\n",
        "llm_response = client.chat.completions.create(\n",
        "    model=\"deepseek/deepseek-r1:free\",\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": system_prompt},\n",
        "        {\"role\":\"user\", \"content\": augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "response = llm_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "nMvvWwGK0tcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#respone = perform_rag(\"Question\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "F1yk8qGA0tek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hhkr3CRf0tgc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}